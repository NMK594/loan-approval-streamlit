{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Danh sách URL của các trang danh mục\n",
    "category_pages = [f\"https://bdshanoi.com.vn/can-ho/next-page-{i}.html\" for i in range(1, 16)]\n",
    "article_links = []\n",
    "\n",
    "for page_url in category_pages:\n",
    "    response = requests.get(page_url)\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    for a_tag in soup.select(\"a[href^='/ban-can-ho-'], a[href^='/can-ho-']\"):  \n",
    "        href = a_tag[\"href\"]\n",
    "        if href.count(\"/\") > 1:\n",
    "            link = \"https://bdshanoi.com.vn\" + a_tag[\"href\"]\n",
    "            if link not in article_links:\n",
    "                article_links.append(link)\n",
    "            if len(article_links) >= 200:\n",
    "                break\n",
    "    if len(article_links) >= 200:\n",
    "        break\n",
    "\n",
    "# Hàm xử lý thông tin thành dictionary\n",
    "def parse_infos(info_list):\n",
    "    info_dict = {}\n",
    "    for item in info_list:\n",
    "        if \":\" in item:\n",
    "            key, value = item.split(\":\", 1)\n",
    "            info_dict[key.strip()] = value.strip()\n",
    "    return info_dict\n",
    "\n",
    "all_attributes = set()\n",
    "data = []\n",
    "\n",
    "# Duyệt từng link bài chi tiết và trích xuất thông tin\n",
    "for url in article_links:\n",
    "    news = requests.get(url)\n",
    "    soup = BeautifulSoup(news.content, \"html.parser\")\n",
    "\n",
    "    div_title = soup.find(\"div\", class_=\"prohead\")\n",
    "    title = div_title.find(\"h1\").text.strip() \n",
    "\n",
    "    div_id = soup.find(\"div\", class_=\"proleft\")\n",
    "    id = div_id.find(\"span\").text.strip() \n",
    "\n",
    "    div_price = soup.find(\"div\", class_=\"proright\")\n",
    "    price = div_price.find(\"span\").text.strip() if div_price and div_price.find(\"span\") else \"Vui lòng liên hệ\"\n",
    "\n",
    "    div_info = soup.find(\"ul\", class_=\"ultech\")\n",
    "    infos = [info.text.strip() for info in div_info.findAll(\"li\")] if div_info else []\n",
    "    parsed_info = parse_infos(infos)\n",
    "    all_attributes.update(parsed_info.keys())\n",
    "\n",
    "    row = {\"title\": title, \"id\": id, \"price\": price}\n",
    "    row.update(parsed_info)\n",
    "    data.append(row)\n",
    "\n",
    "# Chuẩn hóa dữ liệu với tất cả thuộc tính\n",
    "for row in data:\n",
    "    for attr in all_attributes:\n",
    "        row.setdefault(attr, None)\n",
    "\n",
    "# Chuyển dữ liệu thành DataFrame và lưu vào CSV\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"real_estate_data.csv\", index=False)\n",
    "\n",
    "\n",
    "# Hàm xử lý thông tin thành dictionary\n",
    "def parse_infos(info_list):\n",
    "    info_dict = {}\n",
    "    for item in info_list:\n",
    "        if \":\" in item:\n",
    "            key, value = item.split(\":\", 1)\n",
    "            info_dict[key.strip()] = value.strip()\n",
    "    return info_dict\n",
    "\n",
    "all_attributes = set()\n",
    "data = []\n",
    "\n",
    "# Duyệt từng link bài chi tiết và trích xuất thông tin\n",
    "for url in article_links:\n",
    "    news = requests.get(url)\n",
    "    soup = BeautifulSoup(news.content, \"html.parser\")\n",
    "\n",
    "    div_title = soup.find(\"div\", class_=\"prohead\")\n",
    "    title = div_title.find(\"h1\").text.strip() \n",
    "\n",
    "    div_id = soup.find(\"div\", class_=\"proleft\")\n",
    "    id = div_id.find(\"span\").text.strip() \n",
    "\n",
    "    div_price = soup.find(\"div\", class_=\"proright\")\n",
    "    price = div_price.find(\"span\").text.strip() if div_price and div_price.find(\"span\") else \"Vui lòng liên hệ\"\n",
    "\n",
    "    div_info = soup.find(\"ul\", class_=\"ultech\")\n",
    "    infos = [info.text.strip() for info in div_info.findAll(\"li\")] if div_info else []\n",
    "    parsed_info = parse_infos(infos)\n",
    "    all_attributes.update(parsed_info.keys())\n",
    "\n",
    "    row = {\"title\": title, \"id\": id, \"price\": price}\n",
    "    row.update(parsed_info)\n",
    "    data.append(row)\n",
    "\n",
    "# Chuẩn hóa dữ liệu với tất cả thuộc tính\n",
    "for row in data:\n",
    "    for attr in all_attributes:\n",
    "        row.setdefault(attr, None)\n",
    "\n",
    "# Chuyển dữ liệu thành DataFrame và lưu vào CSV\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"real_estate_data.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
